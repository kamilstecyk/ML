{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7885506a-b0d9-4cd9-9fdd-21a1ed963e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â we load our dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)\n",
    "\n",
    "\n",
    "X = data_breast_cancer[\"data\"].iloc[:, [1,8]]\n",
    "y = data_breast_cancer[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8adbdd68-a3ea-46d9-96ee-17c477c0cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "74d9c734-3c48-4725-b2bb-851116984dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we define classifiers\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "lrc = LogisticRegression(random_state=42)\n",
    "nbrs = KNeighborsClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdc538dd-158a-4d53-9972-fcb413c4698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
       "                             ('lr', LogisticRegression(random_state=42)),\n",
       "                             ('knn', KNeighborsClassifier())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we define voting classifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf_hard = VotingClassifier(estimators=[('dt', dtc),('lr', lrc), ('knn', nbrs)],voting='hard')\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators=[('dt', dtc),('lr', lrc), ('knn', nbrs)],voting='soft')\n",
    "\n",
    "\n",
    "# we train our votings classifiers\n",
    "\n",
    "voting_clf_hard.fit(X_train,y_train)\n",
    "voting_clf_soft.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fec65ae4-c989-424c-ba2b-a1d5405c3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we check te accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# firstly we check accuracies for alone classifiers sequentially\n",
    "\n",
    "#accuracy_score(y_true, y_pred)\n",
    "\n",
    "accuracyList = []\n",
    "\n",
    "for clf in voting_clf_hard.estimators_:\n",
    "    \n",
    "    # we predict train set\n",
    "    y_predTrain = clf.predict(X_train)\n",
    "    \n",
    "    # we predict test set\n",
    "    y_predTest = clf.predict(X_test)\n",
    "    \n",
    "    accuracyTrain = accuracy_score(y_train, y_predTrain)\n",
    "    accuracyTest = accuracy_score(y_test, y_predTest)\n",
    "    \n",
    "    accuracyList.append((accuracyTrain,accuracyTest))\n",
    "\n",
    "\n",
    "for clf in [voting_clf_hard,voting_clf_soft]:\n",
    "    \n",
    "    # we predict train set\n",
    "    y_predTrain = clf.predict(X_train)\n",
    "    \n",
    "    # we predict test set\n",
    "    y_predTest = clf.predict(X_test)\n",
    "    \n",
    "    accuracyTrain = accuracy_score(y_train, y_predTrain)\n",
    "    accuracyTest = accuracy_score(y_test, y_predTest)\n",
    "    \n",
    "    accuracyList.append((accuracyTrain,accuracyTest))\n",
    "    \n",
    "    \n",
    "#accuracyList\n",
    "\n",
    "listOfClassifiers = voting_clf_hard.estimators_ + [voting_clf_hard,voting_clf_soft]\n",
    "#listOfClassifiers\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1d6e96ae-8ed9-4e17-bba7-73dbf9bf42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we pickling the data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('acc_vote.pkl', 'wb') as fh:\n",
    "    pickle.dump(accuracyList, fh)\n",
    "\n",
    "\n",
    "with open('vote.pkl', 'wb') as fh:\n",
    "    pickle.dump(listOfClassifiers, fh)\n",
    "\n",
    "# check unpickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae1157cb-5f7f-40bc-acc8-cbfcd68e2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracyList2 = []\n",
    "listOfClassifiers2= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "416415ee-1cbc-4670-84fc-8b1421af57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1 bagging\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,random_state=42,bootstrap=True)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(bag_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1f502698-f05e-4827-bd3c-ee4c60521462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2 bagging with 50 % instances\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "bag_clf50 = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,random_state=42,max_samples=0.5,bootstrap=True)\n",
    "bag_clf50.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(bag_clf50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d4e02831-0ac4-43a6-9afb-3b75b9325815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#3 pasting   ( without repetition of samples )\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "pas_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,random_state=42,bootstrap=False)\n",
    "pas_clf.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(pas_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dee5fb10-2524-4010-82e4-467a3bcc8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#4 pasting with 50 % instances\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "pas_clf50 = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,random_state=42,max_samples=0.5,bootstrap=False)\n",
    "pas_clf50.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(pas_clf50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aaf9e95f-fd5d-49af-8b02-1d9387f3e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4a32842-664b-4afd-a243-bf53d5bded3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 ada boosting\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=30,random_state=42)\n",
    "\n",
    "abc.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a52606b2-8309-4089-9ec1-0ecc02dc57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 gradient boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(n_estimators=30, random_state=42)\n",
    "\n",
    "gbrt.fit(X_train,y_train)\n",
    "\n",
    "listOfClassifiers2.append(gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c0eab8f3-312b-4701-9951-1d1b8f0b2e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30,\n",
      "                  random_state=42), BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=0.5,\n",
      "                  n_estimators=30, random_state=42), BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
      "                  n_estimators=30, random_state=42), BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
      "                  max_samples=0.5, n_estimators=30, random_state=42), RandomForestClassifier(n_estimators=30, random_state=42), AdaBoostClassifier(n_estimators=30, random_state=42), GradientBoostingClassifier(n_estimators=30, random_state=42)]\n",
      "[(0.9956043956043956, 0.6754385964912281), (0.9296703296703297, 0.6842105263157895), (1.0, 0.6228070175438597), (0.9736263736263736, 0.6491228070175439), (0.9956043956043956, 0.6754385964912281), (0.8, 0.7368421052631579), (0.8373626373626374, 0.7105263157894737)]\n"
     ]
    }
   ],
   "source": [
    "print(listOfClassifiers2)\n",
    "\n",
    "# we calculate accuracy\n",
    "\n",
    "\n",
    "for clf2 in listOfClassifiers2:\n",
    "    \n",
    "    # we predict train set\n",
    "    y_predTrain = clf2.predict(X_train)\n",
    "    \n",
    "    # we predict test set\n",
    "    y_predTest = clf2.predict(X_test)\n",
    "    \n",
    "    accuracyTrain = accuracy_score(y_train, y_predTrain)\n",
    "    accuracyTest = accuracy_score(y_test, y_predTest)\n",
    "    \n",
    "    accuracyList2.append((accuracyTrain,accuracyTest))\n",
    "    \n",
    "print(accuracyList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "66b27825-ae99-40e4-b5b8-076c13add8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pickle data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('acc_bag.pkl', 'wb') as fh:\n",
    "    pickle.dump(accuracyList2, fh)\n",
    "\n",
    "\n",
    "with open('bag.pkl', 'wb') as fh:\n",
    "    pickle.dump(listOfClassifiers2, fh)\n",
    "\n",
    "# check unpickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c840fbe2-c141-42b8-9f63-95dc19b27e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we generate second dataset with all features\n",
    "\n",
    "X2 = data_breast_cancer[\"data\"]\n",
    "y2 = data_breast_cancer[\"target\"]\n",
    "\n",
    "\n",
    "# we split into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fb41c48a-297b-4bf3-addb-918aad8fe07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
       "                  max_features=2, max_samples=0.5, n_estimators=30,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bagging with 2 features from all\n",
    " \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "fea_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,random_state=42,bootstrap=False,max_features=2,max_samples=0.5)\n",
    "fea_clf.fit(X_train2,y_train2)\n",
    "\n",
    "fea_clf.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3840c4a7-86ea-4330-bb6d-50cb1fc800df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9736842105263158]\n",
      "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
      "                  max_features=2, max_samples=0.5, n_estimators=30,\n",
      "                  random_state=42)]\n"
     ]
    }
   ],
   "source": [
    "# accuracies\n",
    "\n",
    "# we predict train set\n",
    "y_predTrain2 = fea_clf.predict(X_train2)\n",
    "    \n",
    "# we predict test set\n",
    "y_predTest2 = fea_clf.predict(X_test2)\n",
    "    \n",
    "accuracyTrain = accuracy_score(y_train2, y_predTrain2)\n",
    "accuracyTest = accuracy_score(y_test2, y_predTest2)\n",
    "\n",
    "listAccuracies3 = [accuracyTrain,accuracyTest]\n",
    "classificator = [fea_clf]\n",
    "    \n",
    "print(listAccuracies3)\n",
    "print(classificator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8ce73a6c-9f58-429a-bf84-421eecd34a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pickle data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('acc_fea.pkl', 'wb') as fh:\n",
    "    pickle.dump(listAccuracies3, fh)\n",
    "\n",
    "\n",
    "with open('fea.pkl', 'wb') as fh:\n",
    "    pickle.dump(classificator, fh)\n",
    "\n",
    "# check unpickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6abff92f-cfc0-4c58-88af-6f9e50ad3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Acc_train  Acc_test                                      Features\n",
      "15   0.938462  0.938596          [worst fractal dimension, mean area]\n",
      "11   0.934066  0.938596                    [worst radius, area error]\n",
      "26   0.934066  0.929825               [mean radius, mean compactness]\n",
      "9    0.931868  0.921053                     [mean area, worst radius]\n",
      "6    0.938462  0.912281            [worst perimeter, mean smoothness]\n",
      "19   0.953846  0.894737  [worst concave points, concave points error]\n",
      "1    0.945055  0.894737                 [mean radius, mean concavity]\n",
      "4    0.927473  0.894737          [worst area, mean fractal dimension]\n",
      "7    0.912088  0.885965            [concave points error, area error]\n",
      "29   0.901099  0.885965                 [concavity error, area error]\n",
      "5    0.912088  0.850877                [mean radius, perimeter error]\n",
      "13   0.909890  0.850877               [perimeter error, worst radius]\n",
      "20   0.931868  0.842105             [worst perimeter, symmetry error]\n",
      "25   0.909890  0.833333          [area error, mean fractal dimension]\n",
      "8    0.894505  0.824561             [mean texture, worst compactness]\n",
      "14   0.914286  0.815789    [worst concavity, worst fractal dimension]\n",
      "22   0.870330  0.789474           [perimeter error, smoothness error]\n",
      "10   0.912088  0.780702              [worst concavity, worst texture]\n",
      "24   0.861538  0.728070           [concavity error, mean compactness]\n",
      "16   0.883516  0.710526            [mean smoothness, perimeter error]\n",
      "0    0.865934  0.710526     [worst compactness, concave points error]\n",
      "3    0.830769  0.710526     [mean fractal dimension, concavity error]\n",
      "21   0.832967  0.684211             [mean texture, compactness error]\n",
      "28   0.841758  0.675439      [worst texture, fractal dimension error]\n",
      "2    0.817582  0.666667    [concavity error, fractal dimension error]\n",
      "12   0.813187  0.666667            [symmetry error, worst smoothness]\n",
      "17   0.810989  0.666667        [mean fractal dimension, mean texture]\n",
      "27   0.828571  0.657895         [mean symmetry, concave points error]\n",
      "18   0.835165  0.605263             [smoothness error, worst texture]\n",
      "23   0.817582  0.587719              [mean symmetry, mean smoothness]\n"
     ]
    }
   ],
   "source": [
    "# we create rank of best features for accuracy of estimator\n",
    "\n",
    "#fea_clf.estimators_features_\n",
    "\n",
    "#data_breast_cancer[\"data\"].iloc[:, [25,17]]\n",
    "fea_clf.estimators_features_[0][1]\n",
    "#data_breast_cancer[\"data\"].columns[25]\n",
    "#data_breast_cancer[\"data\"].iloc[:, [1,8]]\n",
    "\n",
    "listAccTrain = []\n",
    "listAccTest = []\n",
    "listFeatures = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for estimator in fea_clf.estimators_:\n",
    "    \n",
    "    \n",
    "    feature1 = fea_clf.estimators_features_[i][0]\n",
    "    feature2 = fea_clf.estimators_features_[i][1]\n",
    "    \n",
    "    listOfFeatures = [data_breast_cancer[\"data\"].columns[feature1],data_breast_cancer[\"data\"].columns[feature2]]\n",
    " \n",
    "    # we predict train set\n",
    "    y_predTrain2 = estimator.predict(X_train2.iloc[:, [feature1,feature2]])\n",
    "    \n",
    "    # we predict test set\n",
    "    y_predTest2 = estimator.predict(X_test2.iloc[:, [feature1,feature2]])\n",
    "    \n",
    "    accuracyTrain = accuracy_score(y_train2, y_predTrain2)\n",
    "    accuracyTest = accuracy_score(y_test2, y_predTest2)\n",
    "    \n",
    "    #print(str(accuracyTrain) + \" : \" +  str(accuracyTest))\n",
    "    #print(str(feature1) + \" ; \" + str(feature2))\n",
    "    #print(listOfFeatures)\n",
    "    \n",
    "    listAccTrain.append(accuracyTrain)\n",
    "    listAccTest.append(accuracyTest)\n",
    "    listFeatures.append(listOfFeatures)\n",
    "    \n",
    "\n",
    "    i += 1\n",
    "\n",
    "data = {\"Acc_train\" : listAccTrain , \"Acc_test\" : listAccTest, \"Features\" : listFeatures}\n",
    "\n",
    "\n",
    "\n",
    "# creating dataframe from dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# we sort values \n",
    "df_sorted = df.sort_values(by=['Acc_test','Acc_train'], ascending=False) \n",
    "print(df_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "356b4b3b-f037-48fe-88ee-5adcf48abc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pickle our rank\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('acc_fea_rank.pkl', 'wb') as fh:\n",
    "    pickle.dump(df_sorted, fh)\n",
    "\n",
    "# unpickling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade14a43-eb37-4d9a-888d-894006daa332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
