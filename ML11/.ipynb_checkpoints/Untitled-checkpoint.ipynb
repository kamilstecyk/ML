{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90df98d0-80d2-4fb0-9ce5-aac0fd62aa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88aea39b-1b78-4023-81ca-a9d9df8c0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "\n",
    "def get_run_logdir(parName,parValue): \n",
    "    run_id = str(time.time()) + \"_\" + str(parName) + \"_\" + str(parValue)\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "#run_logdir = get_run_logdir()\n",
    "#tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40c53018-a1f4-4889-b77a-de2b155134cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_neurons, optimizer, learning_rate, momentum=0):   # regression\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    \n",
    "    model.add(InputLayer(input_shape=(X_train.shape[1], ), name='Input_Layer'))\n",
    "\n",
    "    \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        \n",
    "        \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    optimizer.learning_rate = learning_rate\n",
    "    \n",
    "    if momentum != 0:\n",
    "        optimizer.momentum = momentum\n",
    "        \n",
    "    #optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=optimizer,metrics=[\"mae\"])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d00e112-9d1b-495e-b548-789da6316aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we clean session before experiments\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cleanSession():\n",
    "    # we clean session before experiments\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a18ca4e-4eb1-4ff1-9721-0da6e68aad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,verbose=1,min_delta=1)\n",
    "\n",
    "defaultNOL = 1\n",
    "defaultLR = 0.00001\n",
    "defaultNeuronsOnLayer = 25\n",
    "optimizer = keras.optimizers.SGD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aded9882-1dd2-40ae-a509-196caf88696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 117101.7812 - mae: 123.7935 - val_loss: 108.1399 - val_mae: 8.5337\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 163.8253 - mae: 9.5988 - val_loss: 68.6999 - val_mae: 6.7683\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 113.2871 - mae: 7.8936 - val_loss: 49.6265 - val_mae: 5.5180\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 97.5250 - mae: 7.2386 - val_loss: 44.5197 - val_mae: 5.2958\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 91.5391 - mae: 7.0076 - val_loss: 42.7563 - val_mae: 5.2981\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 87.4378 - mae: 7.0010 - val_loss: 42.5495 - val_mae: 5.0830\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 86.9827 - mae: 6.7954 - val_loss: 41.1674 - val_mae: 5.1446\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.6662 - mae: 6.7517 - val_loss: 44.3108 - val_mae: 5.4583\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.2038 - mae: 6.9364 - val_loss: 40.8578 - val_mae: 5.0159\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.3688 - mae: 6.7019 - val_loss: 44.2814 - val_mae: 5.4409\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3176 - mae: 6.8699 - val_loss: 40.8691 - val_mae: 5.1381\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3014 - mae: 6.7988 - val_loss: 46.5182 - val_mae: 5.6370\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.0942 - mae: 6.7629 - val_loss: 43.3289 - val_mae: 5.3657\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.8896 - mae: 6.8204 - val_loss: 40.6521 - val_mae: 5.0992\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.5033 - mae: 6.7824 - val_loss: 40.2261 - val_mae: 5.0088\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.2646 - mae: 6.7375 - val_loss: 41.3100 - val_mae: 4.9884\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.2253 - mae: 6.5342 - val_loss: 74.1952 - val_mae: 7.3707\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# we do a trail experiment\n",
    "\n",
    "run_logdir = get_run_logdir(\"NOL\",defaultNOL)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "model = build_model(defaultNOL,defaultNeuronsOnLayer,optimizer,defaultLR)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f69d39e3-a0a0-4d09-a5d3-a378977228fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4096.3271 - mae: 52.9450 - val_loss: 518.8672 - val_mae: 19.9679\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 383.5276 - mae: 16.5246 - val_loss: 252.1320 - val_mae: 13.7516\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 292.2751 - mae: 14.2545 - val_loss: 207.5724 - val_mae: 12.1838\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 269.8958 - mae: 13.5324 - val_loss: 189.7364 - val_mae: 11.4592\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 250.9415 - mae: 12.9621 - val_loss: 175.8954 - val_mae: 10.8495\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 233.2527 - mae: 12.3469 - val_loss: 165.9992 - val_mae: 10.4661\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 216.2453 - mae: 11.7595 - val_loss: 148.8138 - val_mae: 9.6089\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 205.2328 - mae: 11.4024 - val_loss: 140.2636 - val_mae: 9.2815\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 194.6108 - mae: 11.0539 - val_loss: 132.9387 - val_mae: 9.0525\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 184.9934 - mae: 10.7585 - val_loss: 126.3792 - val_mae: 8.7792\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 178.4395 - mae: 10.4784 - val_loss: 121.7285 - val_mae: 8.6168\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 170.8442 - mae: 10.1847 - val_loss: 114.9725 - val_mae: 8.3284\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 165.0835 - mae: 9.9493 - val_loss: 107.5997 - val_mae: 8.0336\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 158.3348 - mae: 9.7845 - val_loss: 103.4164 - val_mae: 7.8739\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 153.2291 - mae: 9.6478 - val_loss: 101.2452 - val_mae: 7.7734\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 148.9353 - mae: 9.3815 - val_loss: 95.8061 - val_mae: 7.5583\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 144.4723 - mae: 9.2077 - val_loss: 90.2536 - val_mae: 7.2505\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 141.0471 - mae: 9.2543 - val_loss: 86.1535 - val_mae: 7.1276\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 136.0867 - mae: 9.0232 - val_loss: 83.7605 - val_mae: 7.0151\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 132.8932 - mae: 8.8329 - val_loss: 80.7214 - val_mae: 6.8747\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 129.2280 - mae: 8.6261 - val_loss: 78.1643 - val_mae: 6.7915\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 127.3839 - mae: 8.7387 - val_loss: 74.4831 - val_mae: 6.6338\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 124.2436 - mae: 8.5018 - val_loss: 72.1079 - val_mae: 6.5173\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 122.0525 - mae: 8.4328 - val_loss: 70.6866 - val_mae: 6.4401\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 118.9229 - mae: 8.2484 - val_loss: 67.9987 - val_mae: 6.3445\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 116.2936 - mae: 8.1773 - val_loss: 66.0894 - val_mae: 6.2546\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 114.5285 - mae: 8.0871 - val_loss: 64.1046 - val_mae: 6.1673\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 112.8472 - mae: 8.0456 - val_loss: 62.6871 - val_mae: 6.1019\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 110.7878 - mae: 7.9539 - val_loss: 61.1512 - val_mae: 6.0308\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 108.8908 - mae: 7.8304 - val_loss: 60.0991 - val_mae: 5.9961\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 108.4626 - mae: 7.8667 - val_loss: 58.5848 - val_mae: 5.9278\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 106.2896 - mae: 7.7658 - val_loss: 57.5487 - val_mae: 5.8732\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.4503 - mae: 7.7847 - val_loss: 55.9806 - val_mae: 5.7896\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 103.6273 - mae: 7.6975 - val_loss: 54.6880 - val_mae: 5.7257\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 102.4297 - mae: 7.6092 - val_loss: 53.4230 - val_mae: 5.6657\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 101.3095 - mae: 7.6010 - val_loss: 52.1073 - val_mae: 5.5894\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 99.7458 - mae: 7.4850 - val_loss: 51.1589 - val_mae: 5.5465\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 98.7434 - mae: 7.4926 - val_loss: 50.0886 - val_mae: 5.4877\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.7784 - mae: 7.3528 - val_loss: 49.3774 - val_mae: 5.4656\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.1218 - mae: 7.4585 - val_loss: 48.1659 - val_mae: 5.3839\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 95.8636 - mae: 7.2896 - val_loss: 47.0947 - val_mae: 5.3411\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.6603 - mae: 7.3274 - val_loss: 46.2868 - val_mae: 5.2914\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.0573 - mae: 7.2532 - val_loss: 45.5182 - val_mae: 5.2577\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 93.2147 - mae: 7.1848 - val_loss: 44.7763 - val_mae: 5.2311\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 92.3976 - mae: 7.2071 - val_loss: 44.1425 - val_mae: 5.1912\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.7501 - mae: 7.1649 - val_loss: 43.5403 - val_mae: 5.1457\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.2932 - mae: 7.1613 - val_loss: 42.8852 - val_mae: 5.1542\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.3491 - mae: 7.1059 - val_loss: 42.4343 - val_mae: 5.0816\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.9770 - mae: 7.0379 - val_loss: 41.8225 - val_mae: 5.0564\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.4655 - mae: 6.9714 - val_loss: 41.8056 - val_mae: 5.1257\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.0604 - mae: 7.0725 - val_loss: 41.3184 - val_mae: 5.0982\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.9648 - mae: 6.9764 - val_loss: 40.5908 - val_mae: 5.0564\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.3446 - mae: 6.9756 - val_loss: 39.9802 - val_mae: 5.0146\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.6086 - mae: 6.9429 - val_loss: 39.5035 - val_mae: 4.9862\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.1889 - mae: 6.9299 - val_loss: 38.9171 - val_mae: 4.9362\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.2460 - mae: 6.8773 - val_loss: 38.5089 - val_mae: 4.8895\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.7047 - mae: 6.8136 - val_loss: 38.3135 - val_mae: 4.9085\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.9725 - mae: 6.8493 - val_loss: 37.8553 - val_mae: 4.8478\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.9527 - mae: 6.7607 - val_loss: 38.0235 - val_mae: 4.9045\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.3649 - mae: 6.8252 - val_loss: 37.4431 - val_mae: 4.8600\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.2968 - mae: 6.7679 - val_loss: 37.4086 - val_mae: 4.8668\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.6266 - mae: 6.7617 - val_loss: 36.5059 - val_mae: 4.7738\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.7718 - mae: 6.7029 - val_loss: 37.4196 - val_mae: 4.9130\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.0666 - mae: 6.7883 - val_loss: 36.6177 - val_mae: 4.8352\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.1327 - mae: 6.7579 - val_loss: 35.6220 - val_mae: 4.7254\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.0876 - mae: 6.6189 - val_loss: 35.8229 - val_mae: 4.7674\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.3331 - mae: 6.6238 - val_loss: 35.7737 - val_mae: 4.7863\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 81.5658 - mae: 6.6455 - val_loss: 35.5561 - val_mae: 4.7747\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.9480 - mae: 6.6529 - val_loss: 35.1808 - val_mae: 4.7401\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.6489 - mae: 6.5368 - val_loss: 36.3956 - val_mae: 4.9041\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.7105 - mae: 6.6705 - val_loss: 34.4705 - val_mae: 4.6750\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.0918 - mae: 6.5734 - val_loss: 34.1701 - val_mae: 4.6644\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.1812 - mae: 6.5387 - val_loss: 34.9231 - val_mae: 4.7737\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.5574 - mae: 6.5938 - val_loss: 33.7341 - val_mae: 4.6361\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.7513 - mae: 6.5258 - val_loss: 33.5602 - val_mae: 4.6318\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.2537 - mae: 6.5011 - val_loss: 35.0209 - val_mae: 4.8155\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.7886 - mae: 6.5955 - val_loss: 33.0026 - val_mae: 4.5911\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.6693 - mae: 6.4540 - val_loss: 33.1897 - val_mae: 4.6354\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.2194 - mae: 6.4199 - val_loss: 33.2253 - val_mae: 4.6503\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.1857 - mae: 6.4587 - val_loss: 33.4988 - val_mae: 4.6908\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.1344 - mae: 6.4478 - val_loss: 33.6754 - val_mae: 4.7154\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.2657 - mae: 6.4818 - val_loss: 33.2705 - val_mae: 4.6807\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.6901 - mae: 6.4634 - val_loss: 32.0438 - val_mae: 4.5601\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.4161 - mae: 6.3554 - val_loss: 32.3329 - val_mae: 4.6064\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.3450 - mae: 6.4060 - val_loss: 33.0492 - val_mae: 4.6848\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.3299 - mae: 6.4813 - val_loss: 31.4237 - val_mae: 4.4963\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.7859 - mae: 6.3321 - val_loss: 31.4865 - val_mae: 4.5420\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.5703 - mae: 6.3781 - val_loss: 31.2529 - val_mae: 4.5160\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.4193 - mae: 6.3294 - val_loss: 31.2666 - val_mae: 4.5359\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.1666 - mae: 6.3252 - val_loss: 30.9632 - val_mae: 4.4977\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.7272 - mae: 6.2681 - val_loss: 32.0039 - val_mae: 4.6245\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.8154 - mae: 6.3581 - val_loss: 33.1172 - val_mae: 4.7542\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.8077 - mae: 6.4323 - val_loss: 30.5668 - val_mae: 4.4835\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.4736 - mae: 6.2833 - val_loss: 30.5726 - val_mae: 4.4989\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.1027 - mae: 6.2841 - val_loss: 31.0749 - val_mae: 4.5629\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.4805 - mae: 6.3458 - val_loss: 30.1364 - val_mae: 4.4436\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.1733 - mae: 6.2695 - val_loss: 30.2671 - val_mae: 4.4892\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.9492 - mae: 6.2713 - val_loss: 31.2609 - val_mae: 4.6047\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.6842 - mae: 6.2767 - val_loss: 31.2176 - val_mae: 4.6009\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.4623 - mae: 6.3371 - val_loss: 30.0064 - val_mae: 4.4825\n",
      "74.46226501464844 : loss history ----\n",
      "6.268055438995361 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 154952.1719 - mae: 139.2766 - val_loss: 93.1317 - val_mae: 8.3935\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 126.7701 - mae: 8.8418 - val_loss: 67.5398 - val_mae: 7.0448\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 104.5025 - mae: 7.9278 - val_loss: 54.3043 - val_mae: 6.0271\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.7789 - mae: 7.5516 - val_loss: 49.8669 - val_mae: 5.7833\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.8657 - mae: 7.4181 - val_loss: 48.3643 - val_mae: 5.7447\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.5563 - mae: 7.3624 - val_loss: 46.4693 - val_mae: 5.4405\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.2230 - mae: 7.2277 - val_loss: 45.8077 - val_mae: 5.4510\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.8821 - mae: 7.1939 - val_loss: 50.5788 - val_mae: 5.9678\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 92.1642 - mae: 7.3192 - val_loss: 45.1478 - val_mae: 5.3295\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.1453 - mae: 7.1598 - val_loss: 48.7451 - val_mae: 5.8150\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.3457 - mae: 7.3031 - val_loss: 44.9786 - val_mae: 5.3916\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.9154 - mae: 7.1688 - val_loss: 50.6042 - val_mae: 5.9953\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.9057 - mae: 7.2004 - val_loss: 45.6782 - val_mae: 5.5222\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.5755 - mae: 7.1986 - val_loss: 44.5379 - val_mae: 5.3355\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.0729 - mae: 7.1896 - val_loss: 44.4055 - val_mae: 5.3161\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.4409 - mae: 7.1454 - val_loss: 46.2777 - val_mae: 5.3605\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.4232 - mae: 6.9615 - val_loss: 78.0521 - val_mae: 7.6669\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.4249 - mae: 7.4176 - val_loss: 44.6298 - val_mae: 5.2828\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.4636 - mae: 7.0313 - val_loss: 50.9623 - val_mae: 6.0317\n",
      "Epoch 00019: early stopping\n",
      "88.42317962646484 : loss history ----\n",
      "6.961516380310059 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 884318656.0000 - mae: 11736.8398 - val_loss: 683.2122 - val_mae: 25.3087\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 778.6398 - mae: 26.2564 - val_loss: 680.0544 - val_mae: 25.2463\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 775.3668 - mae: 26.1936 - val_loss: 676.9111 - val_mae: 25.1840\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 772.1083 - mae: 26.1313 - val_loss: 673.7555 - val_mae: 25.1212\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 768.8371 - mae: 26.0687 - val_loss: 670.6077 - val_mae: 25.0585\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 765.5745 - mae: 26.0054 - val_loss: 667.4983 - val_mae: 24.9964\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 762.3500 - mae: 25.9441 - val_loss: 664.3867 - val_mae: 24.9341\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 759.1233 - mae: 25.8820 - val_loss: 661.2794 - val_mae: 24.8717\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 755.9027 - mae: 25.8198 - val_loss: 658.2285 - val_mae: 24.8103\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 752.7368 - mae: 25.7581 - val_loss: 655.1450 - val_mae: 24.7480\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 749.5394 - mae: 25.6956 - val_loss: 652.0958 - val_mae: 24.6864\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 746.3771 - mae: 25.6340 - val_loss: 649.0667 - val_mae: 24.6249\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 743.2349 - mae: 25.5730 - val_loss: 646.0626 - val_mae: 24.5639\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 740.1172 - mae: 25.5116 - val_loss: 643.0538 - val_mae: 24.5025\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 736.9955 - mae: 25.4505 - val_loss: 640.0645 - val_mae: 24.4415\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 733.8945 - mae: 25.3897 - val_loss: 637.1050 - val_mae: 24.3808\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 730.8210 - mae: 25.3295 - val_loss: 634.1030 - val_mae: 24.3192\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 727.7080 - mae: 25.2676 - val_loss: 631.1818 - val_mae: 24.2591\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 724.6743 - mae: 25.2073 - val_loss: 628.2346 - val_mae: 24.1982\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 721.6154 - mae: 25.1465 - val_loss: 625.3298 - val_mae: 24.1381\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 718.5986 - mae: 25.0865 - val_loss: 622.3874 - val_mae: 24.0771\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 715.5447 - mae: 25.0262 - val_loss: 619.4946 - val_mae: 24.0170\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 712.5414 - mae: 24.9658 - val_loss: 616.6320 - val_mae: 23.9573\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 709.5682 - mae: 24.9057 - val_loss: 613.7658 - val_mae: 23.8974\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 706.5916 - mae: 24.8461 - val_loss: 610.9131 - val_mae: 23.8376\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 703.6281 - mae: 24.7862 - val_loss: 608.0808 - val_mae: 23.7782\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 700.6868 - mae: 24.7271 - val_loss: 605.2809 - val_mae: 23.7192\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 697.7769 - mae: 24.6681 - val_loss: 602.4587 - val_mae: 23.6597\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 694.8460 - mae: 24.6084 - val_loss: 599.6724 - val_mae: 23.6007\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 691.9509 - mae: 24.5501 - val_loss: 596.9073 - val_mae: 23.5420\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 689.0764 - mae: 24.4917 - val_loss: 594.1285 - val_mae: 23.4829\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 686.1886 - mae: 24.4325 - val_loss: 591.3799 - val_mae: 23.4244\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 683.3318 - mae: 24.3739 - val_loss: 588.6418 - val_mae: 23.3658\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 680.4846 - mae: 24.3152 - val_loss: 585.8918 - val_mae: 23.3069\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 677.6264 - mae: 24.2563 - val_loss: 583.1712 - val_mae: 23.2485\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 674.7987 - mae: 24.1978 - val_loss: 580.4868 - val_mae: 23.1907\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 672.0063 - mae: 24.1403 - val_loss: 577.7931 - val_mae: 23.1325\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 669.2062 - mae: 24.0819 - val_loss: 575.1378 - val_mae: 23.0751\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 666.4437 - mae: 24.0248 - val_loss: 572.4745 - val_mae: 23.0173\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 663.6746 - mae: 23.9670 - val_loss: 569.8549 - val_mae: 22.9603\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 660.9484 - mae: 23.9096 - val_loss: 567.2001 - val_mae: 22.9024\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 658.1871 - mae: 23.8515 - val_loss: 564.5833 - val_mae: 22.8452\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 655.4641 - mae: 23.7951 - val_loss: 561.9748 - val_mae: 22.7880\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 652.7504 - mae: 23.7385 - val_loss: 559.3881 - val_mae: 22.7312\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 650.0583 - mae: 23.6807 - val_loss: 556.8100 - val_mae: 22.6744\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 647.3759 - mae: 23.6241 - val_loss: 554.2618 - val_mae: 22.6182\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 644.7227 - mae: 23.5678 - val_loss: 551.6956 - val_mae: 22.5614\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 642.0522 - mae: 23.5117 - val_loss: 549.1824 - val_mae: 22.5056\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 639.4354 - mae: 23.4555 - val_loss: 546.6624 - val_mae: 22.4496\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 636.8115 - mae: 23.4001 - val_loss: 544.1452 - val_mae: 22.3934\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 634.1896 - mae: 23.3437 - val_loss: 541.6321 - val_mae: 22.3372\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 631.5728 - mae: 23.2878 - val_loss: 539.1402 - val_mae: 22.2814\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 628.9777 - mae: 23.2315 - val_loss: 536.6574 - val_mae: 22.2256\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 626.3914 - mae: 23.1760 - val_loss: 534.1730 - val_mae: 22.1697\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 623.8029 - mae: 23.1197 - val_loss: 531.7126 - val_mae: 22.1141\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 621.2403 - mae: 23.0642 - val_loss: 529.2723 - val_mae: 22.0588\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 618.6967 - mae: 23.0093 - val_loss: 526.8259 - val_mae: 22.0033\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 616.1479 - mae: 22.9537 - val_loss: 524.4119 - val_mae: 21.9484\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 613.6320 - mae: 22.8993 - val_loss: 521.9950 - val_mae: 21.8933\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 611.1125 - mae: 22.8439 - val_loss: 519.5916 - val_mae: 21.8383\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 608.6077 - mae: 22.7891 - val_loss: 517.2018 - val_mae: 21.7835\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 606.1165 - mae: 22.7343 - val_loss: 514.8394 - val_mae: 21.7292\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 603.6531 - mae: 22.6803 - val_loss: 512.4659 - val_mae: 21.6746\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 601.1788 - mae: 22.6251 - val_loss: 510.1240 - val_mae: 21.6205\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 598.7368 - mae: 22.5711 - val_loss: 507.7986 - val_mae: 21.5666\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 596.3102 - mae: 22.5176 - val_loss: 505.4547 - val_mae: 21.5122\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.8658 - mae: 22.4638 - val_loss: 503.1339 - val_mae: 21.4582\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.4444 - mae: 22.4094 - val_loss: 500.8107 - val_mae: 21.4040\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 589.0204 - mae: 22.3551 - val_loss: 498.5054 - val_mae: 21.3501\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.6154 - mae: 22.3021 - val_loss: 496.2176 - val_mae: 21.2964\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.2285 - mae: 22.2480 - val_loss: 493.9607 - val_mae: 21.2434\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.8731 - mae: 22.1945 - val_loss: 491.7133 - val_mae: 21.1904\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.5271 - mae: 22.1415 - val_loss: 489.4606 - val_mae: 21.1372\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.1756 - mae: 22.0883 - val_loss: 487.2270 - val_mae: 21.0843\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.8440 - mae: 22.0356 - val_loss: 485.0085 - val_mae: 21.0316\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 572.5270 - mae: 21.9831 - val_loss: 482.7842 - val_mae: 20.9787\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 570.2049 - mae: 21.9299 - val_loss: 480.5860 - val_mae: 20.9262\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 567.9088 - mae: 21.8775 - val_loss: 478.3848 - val_mae: 20.8736\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 565.6102 - mae: 21.8256 - val_loss: 476.2147 - val_mae: 20.8215\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 563.3427 - mae: 21.7735 - val_loss: 474.0384 - val_mae: 20.7692\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 561.0689 - mae: 21.7213 - val_loss: 471.8620 - val_mae: 20.7167\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 558.7958 - mae: 21.6688 - val_loss: 469.7089 - val_mae: 20.6647\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 556.5457 - mae: 21.6165 - val_loss: 467.5710 - val_mae: 20.6129\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 554.3113 - mae: 21.5650 - val_loss: 465.4383 - val_mae: 20.5611\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 552.0822 - mae: 21.5132 - val_loss: 463.3063 - val_mae: 20.5092\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 549.8550 - mae: 21.4610 - val_loss: 461.2130 - val_mae: 20.4581\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 547.6656 - mae: 21.4104 - val_loss: 459.1138 - val_mae: 20.4067\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 545.4706 - mae: 21.3589 - val_loss: 457.0239 - val_mae: 20.3554\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 543.2857 - mae: 21.3078 - val_loss: 454.9531 - val_mae: 20.3045\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 541.1207 - mae: 21.2573 - val_loss: 452.9000 - val_mae: 20.2539\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 538.9725 - mae: 21.2064 - val_loss: 450.8374 - val_mae: 20.2029\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 536.8146 - mae: 21.1553 - val_loss: 448.7746 - val_mae: 20.1518\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 534.6570 - mae: 21.1039 - val_loss: 446.7335 - val_mae: 20.1011\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 532.5227 - mae: 21.0536 - val_loss: 444.7326 - val_mae: 20.0513\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 530.4279 - mae: 21.0036 - val_loss: 442.7150 - val_mae: 20.0009\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 528.3171 - mae: 20.9538 - val_loss: 440.7088 - val_mae: 19.9507\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 526.2169 - mae: 20.9032 - val_loss: 438.7006 - val_mae: 19.9003\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 524.1143 - mae: 20.8531 - val_loss: 436.6877 - val_mae: 19.8496\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 522.0079 - mae: 20.8030 - val_loss: 434.7171 - val_mae: 19.7999\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 519.9441 - mae: 20.7531 - val_loss: 432.7440 - val_mae: 19.7500\n",
      "519.944091796875 : loss history ----\n",
      "20.753137588500977 : mae history ----\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# first experiment\n",
    "\n",
    "# we do a trail experiment\n",
    "\n",
    "firstExpResults = []\n",
    "learningRates = [10**-6,10**-5,10**-4]\n",
    "\n",
    "for lr in learningRates:\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    run_logdir = get_run_logdir(\"lr\",lr)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    model = build_model(defaultNOL,defaultNeuronsOnLayer,optimizer,lr)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "    history.history['loss'].sort()\n",
    "    \n",
    "    lossHis = history.history[\"loss\"][0]\n",
    "    print(str(lossHis) + \" : loss history ----\")\n",
    "    \n",
    "    history.history['mae'].sort()\n",
    "    maeHis = history.history['mae'][0]\n",
    "    print(str(maeHis) + \" : mae history ----\")\n",
    "\n",
    "    firstExpResults.append((lr,lossHis,maeHis))\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pickle_out = open(\"lr.pickle\",\"wb\")\n",
    "pickle.dump(firstExpResults, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "cleanSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781606d-8ca7-4564-b715-757f54820dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b72845da-b423-460f-8de7-1b8dde283602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 23076622611530121216.0000 - mae: 1252332160.0000 - val_loss: 23246576973769596731392.0000 - val_mae: 149493415936.0000\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: inf - mae: 561985544284798976.0000 - val_loss: inf - val_mae: 70139267304854126592.0000\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: inf - mae: 287437184603286306990063616.0000 - val_loss: inf - val_mae: 27919251637917839861716353024.0000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: inf - mae: inf - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 00011: early stopping\n",
      "2.307662261153012e+19 : loss history ----\n",
      "1252332160.0 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27487.8145 - mae: 68.7528 - val_loss: 141.2106 - val_mae: 10.2618\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 114.2785 - mae: 7.9339 - val_loss: 33.3307 - val_mae: 4.6906\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.5615 - mae: 5.8832 - val_loss: 24.0613 - val_mae: 3.9130\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 72.4683 - mae: 5.9655 - val_loss: 22.7245 - val_mae: 3.8777\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.5240 - mae: 5.8415 - val_loss: 22.0320 - val_mae: 3.7787\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.1584 - mae: 5.8157 - val_loss: 24.8644 - val_mae: 3.9796\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.9454 - mae: 5.7512 - val_loss: 23.4140 - val_mae: 3.9753\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 68.8693 - mae: 5.6769 - val_loss: 23.5102 - val_mae: 4.0160\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.3540 - mae: 5.7809 - val_loss: 24.0336 - val_mae: 3.9578\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.3704 - mae: 5.6539 - val_loss: 23.8029 - val_mae: 3.9962\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.6290 - mae: 5.8597 - val_loss: 23.5935 - val_mae: 3.9388\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.0006 - mae: 5.7404 - val_loss: 23.7775 - val_mae: 4.0379\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.9824 - mae: 5.6899 - val_loss: 22.9443 - val_mae: 3.9331\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.7911 - mae: 5.6852 - val_loss: 22.9050 - val_mae: 3.9176\n",
      "Epoch 00014: early stopping\n",
      "68.79113006591797 : loss history ----\n",
      "5.653884410858154 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1482.3497 - mae: 26.4900 - val_loss: 29.5039 - val_mae: 4.4369\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 74.5271 - mae: 6.4246 - val_loss: 25.3536 - val_mae: 4.1408\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 72.9564 - mae: 6.2326 - val_loss: 23.3652 - val_mae: 4.0092\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.7789 - mae: 6.1636 - val_loss: 22.9924 - val_mae: 3.9517\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.3198 - mae: 6.0133 - val_loss: 22.8904 - val_mae: 3.9833\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.2654 - mae: 6.0210 - val_loss: 24.1911 - val_mae: 3.9081\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 69.8324 - mae: 5.9614 - val_loss: 21.9388 - val_mae: 3.8612\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.9103 - mae: 5.8813 - val_loss: 25.5820 - val_mae: 4.3225\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.4482 - mae: 6.0452 - val_loss: 24.4035 - val_mae: 3.8854\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.7971 - mae: 5.7535 - val_loss: 25.5010 - val_mae: 4.2891\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.6881 - mae: 5.9491 - val_loss: 26.9863 - val_mae: 4.4159\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.6209 - mae: 5.8828 - val_loss: 33.1057 - val_mae: 4.8374\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.6876 - mae: 5.8659 - val_loss: 22.2588 - val_mae: 4.0161\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3744 - mae: 5.8575 - val_loss: 21.1282 - val_mae: 3.8424\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.0200 - mae: 5.7895 - val_loss: 21.3714 - val_mae: 3.8321\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.7341 - mae: 5.7478 - val_loss: 24.5252 - val_mae: 3.8908\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.5414 - mae: 5.5291 - val_loss: 74.4872 - val_mae: 7.3473\n",
      "Epoch 00017: early stopping\n",
      "64.5413589477539 : loss history ----\n",
      "5.529135227203369 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1590.3394 - mae: 24.3837 - val_loss: 34.8729 - val_mae: 4.8160\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.8988 - mae: 6.2558 - val_loss: 27.8811 - val_mae: 4.2841\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.2480 - mae: 6.1558 - val_loss: 25.2916 - val_mae: 4.1559\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.9867 - mae: 6.0687 - val_loss: 24.7100 - val_mae: 4.1487\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.0650 - mae: 5.9564 - val_loss: 25.0570 - val_mae: 4.2697\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.3749 - mae: 6.0381 - val_loss: 24.8011 - val_mae: 4.0107\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.6029 - mae: 5.9772 - val_loss: 24.4245 - val_mae: 4.1153\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.5601 - mae: 5.8810 - val_loss: 31.8870 - val_mae: 4.8541\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.5741 - mae: 6.0803 - val_loss: 25.6562 - val_mae: 3.9921\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.9593 - mae: 5.7796 - val_loss: 29.5526 - val_mae: 4.7067\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.1137 - mae: 5.9855 - val_loss: 28.0472 - val_mae: 4.5568\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.0303 - mae: 5.8706 - val_loss: 35.8211 - val_mae: 5.1511\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.2739 - mae: 5.8566 - val_loss: 26.1262 - val_mae: 4.4350\n",
      "Epoch 00013: early stopping\n",
      "67.95931243896484 : loss history ----\n",
      "5.779624938964844 : mae history ----\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# second experiment\n",
    "\n",
    "# we do a trail experiment\n",
    "\n",
    "ExpResults = []\n",
    "\n",
    "for hiddenLayers in range (0,4):\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    run_logdir = get_run_logdir(\"hl\",hiddenLayers)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    model = build_model(hiddenLayers,defaultNeuronsOnLayer,optimizer,defaultLR)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "    history.history['loss'].sort()\n",
    "    \n",
    "    lossHis = history.history[\"loss\"][0]\n",
    "    print(str(lossHis) + \" : loss history ----\")\n",
    "    \n",
    "    history.history['mae'].sort()\n",
    "    maeHis = history.history['mae'][0]\n",
    "    print(str(maeHis) + \" : mae history ----\")\n",
    "\n",
    "    ExpResults.append((hiddenLayers,lossHis,maeHis))\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pickle_out = open(\"hl.pickle\",\"wb\")\n",
    "pickle.dump(ExpResults, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "cleanSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76304907-1a33-4009-b17e-862f394b62da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03814a13-9bb8-4178-869a-4db97487a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 94200.5859 - mae: 120.1804 - val_loss: 506.3246 - val_mae: 21.5324\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 597.7783 - mae: 22.5247 - val_loss: 506.0941 - val_mae: 21.5271\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 596.0223 - mae: 22.5045 - val_loss: 505.8639 - val_mae: 21.5217\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 595.4569 - mae: 22.4960 - val_loss: 505.6315 - val_mae: 21.5163\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.9919 - mae: 22.4884 - val_loss: 505.3985 - val_mae: 21.5109\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.7485 - mae: 22.4829 - val_loss: 505.1676 - val_mae: 21.5055\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.5072 - mae: 22.4776 - val_loss: 504.9354 - val_mae: 21.5001\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.2645 - mae: 22.4723 - val_loss: 504.7023 - val_mae: 21.4947\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.0210 - mae: 22.4669 - val_loss: 504.4729 - val_mae: 21.4894\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.7811 - mae: 22.4615 - val_loss: 504.2395 - val_mae: 21.4839\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.5373 - mae: 22.4560 - val_loss: 504.0079 - val_mae: 21.4786\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.2952 - mae: 22.4506 - val_loss: 503.7769 - val_mae: 21.4732\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.0536 - mae: 22.4453 - val_loss: 503.5468 - val_mae: 21.4678\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 592.8132 - mae: 22.4399 - val_loss: 503.3152 - val_mae: 21.4624\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 592.5711 - mae: 22.4345 - val_loss: 503.0842 - val_mae: 21.4570\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 592.3297 - mae: 22.4292 - val_loss: 502.8545 - val_mae: 21.4517\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 592.0895 - mae: 22.4238 - val_loss: 502.6200 - val_mae: 21.4462\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.8445 - mae: 22.4183 - val_loss: 502.3914 - val_mae: 21.4409\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.6055 - mae: 22.4130 - val_loss: 502.1593 - val_mae: 21.4355\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.3630 - mae: 22.4076 - val_loss: 501.9299 - val_mae: 21.4301\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.1231 - mae: 22.4022 - val_loss: 501.6960 - val_mae: 21.4247\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 590.8787 - mae: 22.3968 - val_loss: 501.4653 - val_mae: 21.4193\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 590.6376 - mae: 22.3914 - val_loss: 501.2361 - val_mae: 21.4139\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 590.3981 - mae: 22.3860 - val_loss: 501.0056 - val_mae: 21.4085\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 590.1570 - mae: 22.3807 - val_loss: 500.7751 - val_mae: 21.4032\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 589.9160 - mae: 22.3753 - val_loss: 500.5452 - val_mae: 21.3978\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 589.6758 - mae: 22.3699 - val_loss: 500.3171 - val_mae: 21.3925\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 589.4373 - mae: 22.3646 - val_loss: 500.0859 - val_mae: 21.3871\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 589.1958 - mae: 22.3591 - val_loss: 499.8569 - val_mae: 21.3817\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 588.9562 - mae: 22.3539 - val_loss: 499.6286 - val_mae: 21.3764\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 588.7176 - mae: 22.3485 - val_loss: 499.3979 - val_mae: 21.3710\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 588.4765 - mae: 22.3431 - val_loss: 499.1690 - val_mae: 21.3656\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 588.2372 - mae: 22.3378 - val_loss: 498.9398 - val_mae: 21.3602\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 587.9974 - mae: 22.3324 - val_loss: 498.7085 - val_mae: 21.3548\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.7556 - mae: 22.3270 - val_loss: 498.4786 - val_mae: 21.3494\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.5156 - mae: 22.3216 - val_loss: 498.2511 - val_mae: 21.3441\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.2775 - mae: 22.3163 - val_loss: 498.0215 - val_mae: 21.3387\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.0377 - mae: 22.3109 - val_loss: 497.7944 - val_mae: 21.3334\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.8002 - mae: 22.3056 - val_loss: 497.5655 - val_mae: 21.3281\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 586.5610 - mae: 22.3002 - val_loss: 497.3396 - val_mae: 21.3228\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.3246 - mae: 22.2948 - val_loss: 497.1092 - val_mae: 21.3174\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 586.0839 - mae: 22.2894 - val_loss: 496.8813 - val_mae: 21.3120\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 585.8456 - mae: 22.2841 - val_loss: 496.6532 - val_mae: 21.3067\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.6071 - mae: 22.2788 - val_loss: 496.4259 - val_mae: 21.3013\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.3695 - mae: 22.2734 - val_loss: 496.1985 - val_mae: 21.2960\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.1317 - mae: 22.2681 - val_loss: 495.9727 - val_mae: 21.2907\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.8956 - mae: 22.2628 - val_loss: 495.7442 - val_mae: 21.2853\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.6567 - mae: 22.2575 - val_loss: 495.5196 - val_mae: 21.2800\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.4219 - mae: 22.2521 - val_loss: 495.2934 - val_mae: 21.2747\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.1853 - mae: 22.2469 - val_loss: 495.0663 - val_mae: 21.2694\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.9479 - mae: 22.2415 - val_loss: 494.8386 - val_mae: 21.2640\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.7098 - mae: 22.2362 - val_loss: 494.6118 - val_mae: 21.2587\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.4727 - mae: 22.2308 - val_loss: 494.3849 - val_mae: 21.2534\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.2354 - mae: 22.2255 - val_loss: 494.1567 - val_mae: 21.2480\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.9966 - mae: 22.2201 - val_loss: 493.9299 - val_mae: 21.2427\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.7596 - mae: 22.2147 - val_loss: 493.7038 - val_mae: 21.2373\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.5231 - mae: 22.2094 - val_loss: 493.4762 - val_mae: 21.2320\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.2851 - mae: 22.2041 - val_loss: 493.2506 - val_mae: 21.2267\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.0492 - mae: 22.1988 - val_loss: 493.0236 - val_mae: 21.2213\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.8119 - mae: 22.1934 - val_loss: 492.7971 - val_mae: 21.2160\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.5750 - mae: 22.1881 - val_loss: 492.5707 - val_mae: 21.2106\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.3383 - mae: 22.1828 - val_loss: 492.3460 - val_mae: 21.2053\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.1033 - mae: 22.1775 - val_loss: 492.1193 - val_mae: 21.2000\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.8663 - mae: 22.1721 - val_loss: 491.8945 - val_mae: 21.1947\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.6313 - mae: 22.1668 - val_loss: 491.6704 - val_mae: 21.1894\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.3969 - mae: 22.1615 - val_loss: 491.4435 - val_mae: 21.1840\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.1595 - mae: 22.1562 - val_loss: 491.2178 - val_mae: 21.1787\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.9235 - mae: 22.1508 - val_loss: 490.9908 - val_mae: 21.1734\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.6861 - mae: 22.1455 - val_loss: 490.7647 - val_mae: 21.1680\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.4495 - mae: 22.1402 - val_loss: 490.5392 - val_mae: 21.1627\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.2139 - mae: 22.1348 - val_loss: 490.3158 - val_mae: 21.1574\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 578.9802 - mae: 22.1295 - val_loss: 490.0924 - val_mae: 21.1521\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 578.7465 - mae: 22.1242 - val_loss: 489.8675 - val_mae: 21.1468\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 578.5113 - mae: 22.1189 - val_loss: 489.6434 - val_mae: 21.1415\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 578.2770 - mae: 22.1136 - val_loss: 489.4199 - val_mae: 21.1362\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 578.0432 - mae: 22.1083 - val_loss: 489.1949 - val_mae: 21.1309\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.8077 - mae: 22.1030 - val_loss: 488.9713 - val_mae: 21.1256\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.5740 - mae: 22.0977 - val_loss: 488.7466 - val_mae: 21.1203\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.3391 - mae: 22.0925 - val_loss: 488.5241 - val_mae: 21.1150\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.1063 - mae: 22.0872 - val_loss: 488.3000 - val_mae: 21.1097\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.8719 - mae: 22.0819 - val_loss: 488.0749 - val_mae: 21.1044\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.6365 - mae: 22.0765 - val_loss: 487.8511 - val_mae: 21.0991\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.4023 - mae: 22.0712 - val_loss: 487.6280 - val_mae: 21.0938\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.1689 - mae: 22.0659 - val_loss: 487.4044 - val_mae: 21.0885\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.9351 - mae: 22.0606 - val_loss: 487.1799 - val_mae: 21.0832\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.7004 - mae: 22.0553 - val_loss: 486.9584 - val_mae: 21.0779\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.4687 - mae: 22.0501 - val_loss: 486.7355 - val_mae: 21.0726\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.2354 - mae: 22.0448 - val_loss: 486.5125 - val_mae: 21.0673\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.0021 - mae: 22.0395 - val_loss: 486.2905 - val_mae: 21.0621\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.7700 - mae: 22.0343 - val_loss: 486.0694 - val_mae: 21.0568\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.5386 - mae: 22.0290 - val_loss: 485.8465 - val_mae: 21.0515\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.3053 - mae: 22.0237 - val_loss: 485.6224 - val_mae: 21.0462\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.0710 - mae: 22.0183 - val_loss: 485.3998 - val_mae: 21.0409\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.8383 - mae: 22.0131 - val_loss: 485.1805 - val_mae: 21.0357\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.6087 - mae: 22.0078 - val_loss: 484.9584 - val_mae: 21.0304\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.3764 - mae: 22.0026 - val_loss: 484.7365 - val_mae: 21.0252\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.1443 - mae: 21.9973 - val_loss: 484.5136 - val_mae: 21.0198\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 572.9111 - mae: 21.9920 - val_loss: 484.2893 - val_mae: 21.0145\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 572.6765 - mae: 21.9867 - val_loss: 484.0685 - val_mae: 21.0093\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 572.4454 - mae: 21.9814 - val_loss: 483.8465 - val_mae: 21.0040\n",
      "572.4453735351562 : loss history ----\n",
      "21.981433868408203 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 41274.6211 - mae: 79.5151 - val_loss: 76.0540 - val_mae: 7.0368\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 101.9324 - mae: 7.1036 - val_loss: 46.6501 - val_mae: 5.3450\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.8588 - mae: 6.2735 - val_loss: 34.9994 - val_mae: 4.7891\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.3199 - mae: 6.0754 - val_loss: 31.7414 - val_mae: 4.5105\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.2903 - mae: 5.9016 - val_loss: 29.4919 - val_mae: 4.3646\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.1264 - mae: 5.8882 - val_loss: 29.9870 - val_mae: 4.3326\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.4882 - mae: 5.6591 - val_loss: 25.8655 - val_mae: 4.0768\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.6390 - mae: 5.6508 - val_loss: 26.5095 - val_mae: 4.1974\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.9034 - mae: 5.8124 - val_loss: 24.9150 - val_mae: 3.9392\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.0059 - mae: 5.5610 - val_loss: 25.3636 - val_mae: 4.1584\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.4468 - mae: 5.8218 - val_loss: 24.0104 - val_mae: 3.9832\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.0565 - mae: 5.7244 - val_loss: 26.5897 - val_mae: 4.2820\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.9558 - mae: 5.6706 - val_loss: 24.9144 - val_mae: 4.1318\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.6576 - mae: 5.7452 - val_loss: 23.1319 - val_mae: 3.9151\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.8953 - mae: 5.7257 - val_loss: 22.7394 - val_mae: 3.7792\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.6049 - mae: 5.6456 - val_loss: 22.3422 - val_mae: 3.7108\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.8299 - mae: 5.5166 - val_loss: 43.2285 - val_mae: 5.4411\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.9211 - mae: 5.8914 - val_loss: 22.5655 - val_mae: 3.7276\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.2642 - mae: 5.5974 - val_loss: 23.4235 - val_mae: 3.9594\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.6258 - mae: 5.6519 - val_loss: 22.2277 - val_mae: 3.7437\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3989 - mae: 5.5251 - val_loss: 40.5426 - val_mae: 5.3174\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.9136 - mae: 5.7532 - val_loss: 27.7271 - val_mae: 4.4123\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.9587 - mae: 5.6913 - val_loss: 21.6860 - val_mae: 3.6320\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3523 - mae: 5.5631 - val_loss: 22.6179 - val_mae: 3.8824\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3579 - mae: 5.6567 - val_loss: 22.0779 - val_mae: 3.7932\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.5943 - mae: 5.5475 - val_loss: 21.7794 - val_mae: 3.6547\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.3799 - mae: 5.5227 - val_loss: 23.3854 - val_mae: 3.8109\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.5735 - mae: 5.5297 - val_loss: 22.5436 - val_mae: 3.8773\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.9316 - mae: 5.6096 - val_loss: 21.7912 - val_mae: 3.6642\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.5450 - mae: 5.4782 - val_loss: 24.5761 - val_mae: 4.1301\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.7590 - mae: 5.5808 - val_loss: 21.4557 - val_mae: 3.6779\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.8266 - mae: 5.4506 - val_loss: 22.0157 - val_mae: 3.8146\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 65.7521 - mae: 5.5964 - val_loss: 21.4974 - val_mae: 3.7131\n",
      "Epoch 00033: early stopping\n",
      "64.82655334472656 : loss history ----\n",
      "5.45059061050415 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 81867.7500 - mae: 114.3551 - val_loss: 514.9318 - val_mae: 21.7193\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 600.8755 - mae: 22.6083 - val_loss: 506.0137 - val_mae: 21.4741\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.9103 - mae: 22.4315 - val_loss: 501.4502 - val_mae: 21.3027\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.3248 - mae: 22.2872 - val_loss: 497.9492 - val_mae: 21.1342\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 588.4079 - mae: 22.1463 - val_loss: 495.1442 - val_mae: 20.9688\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.1255 - mae: 22.0213 - val_loss: 492.8367 - val_mae: 20.8204\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.2075 - mae: 21.9016 - val_loss: 490.6324 - val_mae: 20.7070\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 581.6132 - mae: 21.7832 - val_loss: 485.1728 - val_mae: 20.4796\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 559.6089 - mae: 21.1184 - val_loss: 392.9125 - val_mae: 18.0459\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 294.2542 - mae: 14.0801 - val_loss: 148.1512 - val_mae: 10.3764\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 177.1024 - mae: 10.4494 - val_loss: 106.9651 - val_mae: 8.8947\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 148.8733 - mae: 9.3303 - val_loss: 86.8702 - val_mae: 7.9247\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 130.6020 - mae: 8.5556 - val_loss: 69.5156 - val_mae: 7.0952\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 116.5595 - mae: 7.8913 - val_loss: 59.1672 - val_mae: 6.4458\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 107.3081 - mae: 7.6177 - val_loss: 53.3463 - val_mae: 6.0661\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 101.8426 - mae: 7.2557 - val_loss: 48.4899 - val_mae: 5.7231\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 96.2233 - mae: 7.0194 - val_loss: 66.7351 - val_mae: 6.5613\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.5147 - mae: 7.3593 - val_loss: 43.5212 - val_mae: 5.2736\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.6956 - mae: 6.8500 - val_loss: 40.2056 - val_mae: 5.0550\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.4933 - mae: 6.8586 - val_loss: 38.4018 - val_mae: 4.9123\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3740 - mae: 6.6805 - val_loss: 52.0462 - val_mae: 5.8486\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.5536 - mae: 6.8102 - val_loss: 38.3676 - val_mae: 4.8803\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.2836 - mae: 6.6688 - val_loss: 34.5955 - val_mae: 4.7244\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.5830 - mae: 6.5429 - val_loss: 33.5648 - val_mae: 4.6530\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.8621 - mae: 6.5020 - val_loss: 32.8385 - val_mae: 4.6054\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.7949 - mae: 6.3718 - val_loss: 29.7564 - val_mae: 4.4039\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.0000 - mae: 6.2813 - val_loss: 29.6673 - val_mae: 4.3890\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.4269 - mae: 6.2078 - val_loss: 29.1856 - val_mae: 4.3599\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.7653 - mae: 6.3422 - val_loss: 27.5108 - val_mae: 4.2353\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.1111 - mae: 6.1686 - val_loss: 31.2376 - val_mae: 4.6081\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.2563 - mae: 6.2830 - val_loss: 28.0882 - val_mae: 4.2941\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.4373 - mae: 6.1558 - val_loss: 29.1907 - val_mae: 4.4530\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.8211 - mae: 6.2795 - val_loss: 27.3129 - val_mae: 4.2595\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.5328 - mae: 6.1869 - val_loss: 31.1261 - val_mae: 4.6501\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.3136 - mae: 6.1554 - val_loss: 30.2435 - val_mae: 4.5899\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.1131 - mae: 6.2440 - val_loss: 26.0196 - val_mae: 4.1723\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.3118 - mae: 6.0695 - val_loss: 27.5100 - val_mae: 4.3900\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.5675 - mae: 6.1809 - val_loss: 27.1998 - val_mae: 4.2506\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.7028 - mae: 6.0188 - val_loss: 30.2656 - val_mae: 4.6077\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 74.0862 - mae: 6.2583 - val_loss: 27.4298 - val_mae: 4.2611\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.1359 - mae: 6.0858 - val_loss: 29.8487 - val_mae: 4.5877\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.5034 - mae: 6.1857 - val_loss: 26.6789 - val_mae: 4.2900\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.4967 - mae: 6.1237 - val_loss: 25.3662 - val_mae: 4.1343\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.6365 - mae: 6.0734 - val_loss: 25.5679 - val_mae: 4.1682\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.3393 - mae: 6.0716 - val_loss: 27.2674 - val_mae: 4.3812\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.1162 - mae: 6.1384 - val_loss: 25.3022 - val_mae: 4.1703\n",
      "Epoch 00046: early stopping\n",
      "72.11615753173828 : loss history ----\n",
      "6.018813133239746 : mae history ----\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# third experiment\n",
    "\n",
    "# we do a trail experiment\n",
    "\n",
    "ExpResults = []\n",
    "\n",
    "neuronsNumber = [ 5,25,125]\n",
    "\n",
    "for nn in neuronsNumber:\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    run_logdir = get_run_logdir(\"nn\",nn)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    model = build_model(defaultNOL,nn,optimizer,defaultLR)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "    history.history['loss'].sort()\n",
    "    \n",
    "    lossHis = history.history[\"loss\"][0]\n",
    "    print(str(lossHis) + \" : loss history ----\")\n",
    "    \n",
    "    history.history['mae'].sort()\n",
    "    maeHis = history.history['mae'][0]\n",
    "    print(str(maeHis) + \" : mae history ----\")\n",
    "\n",
    "    ExpResults.append((nn,lossHis,maeHis))\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pickle_out = open(\"nn.pickle\",\"wb\")\n",
    "pickle.dump(ExpResults, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "cleanSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "626c5998-ed57-4637-b835-dd5762030e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18364.6250 - mae: 70.6032 - val_loss: 476.3759 - val_mae: 20.2972\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 499.4724 - mae: 19.2305 - val_loss: 372.6682 - val_mae: 16.8553\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 338.9782 - mae: 15.5225 - val_loss: 227.2440 - val_mae: 13.2693\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 251.6363 - mae: 12.8722 - val_loss: 182.0858 - val_mae: 11.7288\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 220.5141 - mae: 11.8774 - val_loss: 153.6602 - val_mae: 10.7563\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 209.8797 - mae: 11.6350 - val_loss: 148.6651 - val_mae: 10.5676\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 187.0907 - mae: 10.8322 - val_loss: 133.1792 - val_mae: 9.7390\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 181.1816 - mae: 10.4469 - val_loss: 118.4319 - val_mae: 9.3136\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 175.3257 - mae: 10.2194 - val_loss: 147.0011 - val_mae: 10.1729\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 170.2939 - mae: 10.1438 - val_loss: 105.2846 - val_mae: 8.7142\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 165.0861 - mae: 9.8268 - val_loss: 99.1882 - val_mae: 8.5609\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 160.8766 - mae: 9.6225 - val_loss: 143.4350 - val_mae: 9.9700\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 155.2668 - mae: 9.5081 - val_loss: 96.3732 - val_mae: 8.2942\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 135.9987 - mae: 8.6710 - val_loss: 67.9729 - val_mae: 6.7750\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 116.5316 - mae: 8.0648 - val_loss: 55.3220 - val_mae: 5.9925\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 101.9429 - mae: 7.4929 - val_loss: 55.9186 - val_mae: 5.6985\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 89.5707 - mae: 6.8764 - val_loss: 157.2482 - val_mae: 10.8173\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 101.9991 - mae: 7.5673 - val_loss: 49.0505 - val_mae: 5.3675\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.3160 - mae: 6.8109 - val_loss: 36.8276 - val_mae: 4.9349\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.7380 - mae: 6.8243 - val_loss: 33.6665 - val_mae: 4.4988\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 82.6414 - mae: 6.6348 - val_loss: 103.1681 - val_mae: 8.9343\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.5819 - mae: 6.9578 - val_loss: 46.2298 - val_mae: 5.8376\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.9296 - mae: 6.7316 - val_loss: 32.5708 - val_mae: 4.4460\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.2681 - mae: 6.9839 - val_loss: 36.6876 - val_mae: 5.0775\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 86.8778 - mae: 6.8850 - val_loss: 43.6942 - val_mae: 5.6770\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 80.9592 - mae: 6.5950 - val_loss: 34.9419 - val_mae: 4.5632\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.2800 - mae: 6.4451 - val_loss: 40.6302 - val_mae: 4.8162\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.5074 - mae: 6.4475 - val_loss: 33.1906 - val_mae: 4.7594\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 83.1118 - mae: 6.6183 - val_loss: 31.4762 - val_mae: 4.5046\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.4020 - mae: 6.5583 - val_loss: 36.7346 - val_mae: 5.1283\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 83.0487 - mae: 6.6076 - val_loss: 32.0673 - val_mae: 4.6218\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.3935 - mae: 6.3593 - val_loss: 36.1833 - val_mae: 5.0941\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 82.9601 - mae: 6.6298 - val_loss: 31.2649 - val_mae: 4.5359\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 80.6221 - mae: 6.5266 - val_loss: 50.5434 - val_mae: 6.2111\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.9674 - mae: 6.4984 - val_loss: 39.3600 - val_mae: 5.3915\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.9558 - mae: 6.5114 - val_loss: 31.3231 - val_mae: 4.4212\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.4170 - mae: 6.3881 - val_loss: 32.9900 - val_mae: 4.8328\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 79.4690 - mae: 6.4709 - val_loss: 46.5261 - val_mae: 5.2407\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.9473 - mae: 6.4723 - val_loss: 35.7468 - val_mae: 5.0874\n",
      "Epoch 00039: early stopping\n",
      "78.39347076416016 : loss history ----\n",
      "6.359309673309326 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6137.1279 - mae: 48.4875 - val_loss: 454.5816 - val_mae: 19.1656\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 504.7884 - mae: 19.3641 - val_loss: 430.1860 - val_mae: 18.2145\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 456.9429 - mae: 18.2319 - val_loss: 320.0291 - val_mae: 15.6802\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 294.1154 - mae: 14.0863 - val_loss: 142.9266 - val_mae: 10.3629\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 167.8612 - mae: 10.0263 - val_loss: 73.7859 - val_mae: 6.9981\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 122.2805 - mae: 8.3305 - val_loss: 66.0889 - val_mae: 6.3050\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 101.7125 - mae: 7.4943 - val_loss: 62.4634 - val_mae: 6.3271\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 95.9736 - mae: 7.3045 - val_loss: 42.4788 - val_mae: 5.3042\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 90.3931 - mae: 7.1386 - val_loss: 44.9392 - val_mae: 5.1252\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 84.4150 - mae: 6.7263 - val_loss: 36.4631 - val_mae: 4.7803\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.6037 - mae: 7.1604 - val_loss: 34.5445 - val_mae: 4.7939\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.3489 - mae: 6.6710 - val_loss: 34.0239 - val_mae: 4.7309\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 81.1454 - mae: 6.6930 - val_loss: 31.3744 - val_mae: 4.4656\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 81.8334 - mae: 6.6760 - val_loss: 33.8745 - val_mae: 4.5606\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 80.4526 - mae: 6.6907 - val_loss: 32.7926 - val_mae: 4.5293\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.0804 - mae: 6.5173 - val_loss: 33.5358 - val_mae: 4.5391\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.2678 - mae: 6.1835 - val_loss: 98.0025 - val_mae: 8.5249\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.5156 - mae: 6.7994 - val_loss: 31.4774 - val_mae: 4.4360\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 77.8780 - mae: 6.2809 - val_loss: 29.9289 - val_mae: 4.4706\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.8624 - mae: 6.4292 - val_loss: 30.7548 - val_mae: 4.3939\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.4451 - mae: 6.2751 - val_loss: 79.4949 - val_mae: 7.5310\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.1811 - mae: 6.5464 - val_loss: 34.9758 - val_mae: 4.9447\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.7372 - mae: 6.3429 - val_loss: 28.0090 - val_mae: 4.2640\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.9442 - mae: 6.3911 - val_loss: 29.3208 - val_mae: 4.4840\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.6717 - mae: 6.3762 - val_loss: 32.2192 - val_mae: 4.7105\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 73.5263 - mae: 6.1956 - val_loss: 27.6406 - val_mae: 4.2106\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.1915 - mae: 6.1697 - val_loss: 29.8700 - val_mae: 4.3725\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.5767 - mae: 6.0391 - val_loss: 27.9833 - val_mae: 4.3470\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.0182 - mae: 6.2953 - val_loss: 27.3356 - val_mae: 4.2146\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.3765 - mae: 6.1194 - val_loss: 35.0257 - val_mae: 4.9696\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.2151 - mae: 6.3453 - val_loss: 28.0110 - val_mae: 4.3120\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.4894 - mae: 6.0249 - val_loss: 29.5061 - val_mae: 4.4541\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.5200 - mae: 6.1969 - val_loss: 27.6210 - val_mae: 4.2995\n",
      "Epoch 00033: early stopping\n",
      "72.48943328857422 : loss history ----\n",
      "6.024930477142334 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4407.1748 - mae: 36.4299 - val_loss: 60.3402 - val_mae: 6.4210\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 98.5574 - mae: 7.1817 - val_loss: 57.7207 - val_mae: 6.0618\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.5531 - mae: 6.6715 - val_loss: 32.4047 - val_mae: 4.4891\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.5527 - mae: 6.1825 - val_loss: 29.2437 - val_mae: 4.2890\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.5955 - mae: 6.0515 - val_loss: 27.2332 - val_mae: 4.1787\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.4794 - mae: 5.8766 - val_loss: 31.1287 - val_mae: 4.4449\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.6314 - mae: 5.8557 - val_loss: 26.3296 - val_mae: 4.1007\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.2254 - mae: 5.8927 - val_loss: 25.7432 - val_mae: 4.0558\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.7012 - mae: 5.9907 - val_loss: 27.3528 - val_mae: 4.1556\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.1208 - mae: 5.7699 - val_loss: 27.0735 - val_mae: 4.2473\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.1662 - mae: 5.9745 - val_loss: 25.1350 - val_mae: 4.0248\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.8951 - mae: 6.0024 - val_loss: 33.4869 - val_mae: 4.8709\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.0428 - mae: 6.0718 - val_loss: 28.3940 - val_mae: 4.4065\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.4408 - mae: 5.8730 - val_loss: 24.6098 - val_mae: 4.0302\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.8237 - mae: 5.7998 - val_loss: 24.4240 - val_mae: 4.0495\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.6875 - mae: 5.7908 - val_loss: 24.4051 - val_mae: 4.0239\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.1573 - mae: 5.5754 - val_loss: 60.1813 - val_mae: 6.5900\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.6862 - mae: 6.1781 - val_loss: 24.9563 - val_mae: 4.0084\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.9806 - mae: 5.5999 - val_loss: 23.7429 - val_mae: 3.9823\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.9895 - mae: 5.6418 - val_loss: 24.3040 - val_mae: 4.0058\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.5972 - mae: 5.6871 - val_loss: 41.7564 - val_mae: 5.5188\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.1495 - mae: 5.8397 - val_loss: 30.2094 - val_mae: 4.6196\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3449 - mae: 5.8036 - val_loss: 23.8714 - val_mae: 3.9188\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.5070 - mae: 5.6400 - val_loss: 23.5865 - val_mae: 3.9525\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.4071 - mae: 5.7309 - val_loss: 23.9349 - val_mae: 3.9998\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.4002 - mae: 5.5726 - val_loss: 22.8147 - val_mae: 3.8619\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.2218 - mae: 5.5648 - val_loss: 27.0838 - val_mae: 4.1323\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 67.4001 - mae: 5.5794 - val_loss: 23.5908 - val_mae: 3.9632\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.8949 - mae: 5.6739 - val_loss: 24.0699 - val_mae: 3.9001\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.3307 - mae: 5.4868 - val_loss: 25.1155 - val_mae: 4.1376\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.9064 - mae: 5.6252 - val_loss: 22.7705 - val_mae: 3.8198\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.4094 - mae: 5.3638 - val_loss: 24.8436 - val_mae: 4.1512\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.9818 - mae: 5.6360 - val_loss: 22.1276 - val_mae: 3.8109\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.5789 - mae: 5.5487 - val_loss: 24.6362 - val_mae: 4.1404\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.3170 - mae: 5.5490 - val_loss: 28.2493 - val_mae: 4.4873\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.4494 - mae: 5.7742 - val_loss: 22.6362 - val_mae: 3.7910\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.4907 - mae: 5.5369 - val_loss: 22.1226 - val_mae: 3.8510\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.8009 - mae: 5.6126 - val_loss: 23.4598 - val_mae: 3.7911\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.6531 - mae: 5.4506 - val_loss: 25.6043 - val_mae: 4.2303\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.0312 - mae: 5.6589 - val_loss: 24.1284 - val_mae: 3.7948\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 65.0570 - mae: 5.5185 - val_loss: 24.3418 - val_mae: 4.0687\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.2754 - mae: 5.6620 - val_loss: 21.3633 - val_mae: 3.8057\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.2296 - mae: 5.5018 - val_loss: 20.9863 - val_mae: 3.6792\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.8881 - mae: 5.5419 - val_loss: 21.1735 - val_mae: 3.7194\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 62.6437 - mae: 5.3970 - val_loss: 22.8476 - val_mae: 3.9212\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.5663 - mae: 5.5775 - val_loss: 21.3652 - val_mae: 3.7601\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.0480 - mae: 5.5962 - val_loss: 21.0082 - val_mae: 3.7182\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.1432 - mae: 5.5211 - val_loss: 21.1020 - val_mae: 3.7339\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.2770 - mae: 5.4638 - val_loss: 21.1682 - val_mae: 3.7024\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 63.9502 - mae: 5.4974 - val_loss: 29.9217 - val_mae: 4.6652\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 61.9506 - mae: 5.5605 - val_loss: 23.1942 - val_mae: 4.0050\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 61.4229 - mae: 5.4974 - val_loss: 23.8638 - val_mae: 4.0696\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.0782 - mae: 5.5389 - val_loss: 22.5499 - val_mae: 3.9361\n",
      "Epoch 00053: early stopping\n",
      "61.42289352416992 : loss history ----\n",
      "5.363759517669678 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 171.4443 - mae: 10.1510 - val_loss: 118.3621 - val_mae: 9.0396\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 170.1017 - mae: 10.0976 - val_loss: 117.0563 - val_mae: 8.9807\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 168.7736 - mae: 10.0440 - val_loss: 115.7098 - val_mae: 8.9192\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 167.5011 - mae: 9.9902 - val_loss: 114.3199 - val_mae: 8.8546\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 166.1096 - mae: 9.9373 - val_loss: 113.0505 - val_mae: 8.7974\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 164.8296 - mae: 9.8876 - val_loss: 111.7979 - val_mae: 8.7404\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 163.5151 - mae: 9.8364 - val_loss: 110.4838 - val_mae: 8.6800\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 162.2090 - mae: 9.7830 - val_loss: 109.2063 - val_mae: 8.6205\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 160.9297 - mae: 9.7328 - val_loss: 107.9830 - val_mae: 8.5628\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 159.6984 - mae: 9.6833 - val_loss: 106.7625 - val_mae: 8.5047\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 158.5026 - mae: 9.6337 - val_loss: 105.5653 - val_mae: 8.4466\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 157.2574 - mae: 9.5846 - val_loss: 104.4292 - val_mae: 8.3911\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 156.1046 - mae: 9.5326 - val_loss: 103.1843 - val_mae: 8.3306\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 154.9221 - mae: 9.4814 - val_loss: 102.0255 - val_mae: 8.2731\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 153.7760 - mae: 9.4319 - val_loss: 100.8851 - val_mae: 8.2165\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 152.6292 - mae: 9.3821 - val_loss: 99.6861 - val_mae: 8.1655\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 151.5123 - mae: 9.3310 - val_loss: 98.5431 - val_mae: 8.1163\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 150.3772 - mae: 9.2824 - val_loss: 97.5278 - val_mae: 8.0685\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 149.3024 - mae: 9.2404 - val_loss: 96.4764 - val_mae: 8.0207\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 148.2117 - mae: 9.1923 - val_loss: 95.3790 - val_mae: 7.9707\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 147.1620 - mae: 9.1432 - val_loss: 94.2528 - val_mae: 7.9226\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 146.0571 - mae: 9.0963 - val_loss: 93.2828 - val_mae: 7.8768\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 145.0746 - mae: 9.0551 - val_loss: 92.3076 - val_mae: 7.8311\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 144.0914 - mae: 9.0142 - val_loss: 91.3748 - val_mae: 7.7864\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 143.0971 - mae: 8.9696 - val_loss: 90.3680 - val_mae: 7.7414\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 142.1159 - mae: 8.9258 - val_loss: 89.4540 - val_mae: 7.6971\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 141.1976 - mae: 8.8837 - val_loss: 88.5158 - val_mae: 7.6545\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 140.2390 - mae: 8.8409 - val_loss: 87.6219 - val_mae: 7.6143\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 139.3566 - mae: 8.8005 - val_loss: 86.7268 - val_mae: 7.5716\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 138.4806 - mae: 8.7581 - val_loss: 85.8280 - val_mae: 7.5314\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 137.6201 - mae: 8.7160 - val_loss: 84.9347 - val_mae: 7.4910\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 136.6982 - mae: 8.6740 - val_loss: 84.1205 - val_mae: 7.4501\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 135.8280 - mae: 8.6377 - val_loss: 83.3531 - val_mae: 7.4118\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 135.0363 - mae: 8.6029 - val_loss: 82.5339 - val_mae: 7.3709\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 134.1855 - mae: 8.5669 - val_loss: 81.7452 - val_mae: 7.3307\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 133.3929 - mae: 8.5290 - val_loss: 80.9352 - val_mae: 7.2891\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 132.5326 - mae: 8.4914 - val_loss: 80.1437 - val_mae: 7.2499\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 131.7804 - mae: 8.4553 - val_loss: 79.3695 - val_mae: 7.2086\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 130.9762 - mae: 8.4170 - val_loss: 78.5918 - val_mae: 7.1708\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 130.2312 - mae: 8.3828 - val_loss: 77.8676 - val_mae: 7.1322\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 129.4825 - mae: 8.3484 - val_loss: 77.1218 - val_mae: 7.0940\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 128.7693 - mae: 8.3153 - val_loss: 76.4127 - val_mae: 7.0539\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 128.0264 - mae: 8.2801 - val_loss: 75.6892 - val_mae: 7.0165\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 127.3222 - mae: 8.2459 - val_loss: 74.9670 - val_mae: 6.9790\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 126.6082 - mae: 8.2126 - val_loss: 74.3328 - val_mae: 6.9420\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 125.9016 - mae: 8.1784 - val_loss: 73.5972 - val_mae: 6.9030\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 125.2144 - mae: 8.1426 - val_loss: 72.8653 - val_mae: 6.8637\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 124.5423 - mae: 8.1080 - val_loss: 72.1711 - val_mae: 6.8253\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 123.8483 - mae: 8.0769 - val_loss: 71.5062 - val_mae: 6.7883\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 123.2520 - mae: 8.0429 - val_loss: 70.8304 - val_mae: 6.7528\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 122.6113 - mae: 8.0134 - val_loss: 70.2523 - val_mae: 6.7168\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 121.9778 - mae: 7.9866 - val_loss: 69.7264 - val_mae: 6.6835\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 121.4168 - mae: 7.9640 - val_loss: 69.1787 - val_mae: 6.6509\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 120.8048 - mae: 7.9376 - val_loss: 68.6755 - val_mae: 6.6213\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 120.2418 - mae: 7.9159 - val_loss: 68.1691 - val_mae: 6.5900\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 119.6804 - mae: 7.8938 - val_loss: 67.6626 - val_mae: 6.5593\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 119.1010 - mae: 7.8658 - val_loss: 67.1187 - val_mae: 6.5281\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 118.5795 - mae: 7.8447 - val_loss: 66.6382 - val_mae: 6.4975\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 118.0366 - mae: 7.8188 - val_loss: 66.0761 - val_mae: 6.4653\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 117.5010 - mae: 7.7947 - val_loss: 65.6137 - val_mae: 6.4354\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 117.0034 - mae: 7.7743 - val_loss: 65.1374 - val_mae: 6.4053\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 116.4828 - mae: 7.7556 - val_loss: 64.7083 - val_mae: 6.3771\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 116.0082 - mae: 7.7331 - val_loss: 64.2186 - val_mae: 6.3477\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 115.5519 - mae: 7.7161 - val_loss: 63.8190 - val_mae: 6.3197\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 115.0783 - mae: 7.6980 - val_loss: 63.4329 - val_mae: 6.2923\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 114.6072 - mae: 7.6789 - val_loss: 62.9263 - val_mae: 6.2609\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 114.1187 - mae: 7.6575 - val_loss: 62.4832 - val_mae: 6.2332\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 113.6739 - mae: 7.6403 - val_loss: 62.0573 - val_mae: 6.2060\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 113.2256 - mae: 7.6265 - val_loss: 61.7020 - val_mae: 6.1817\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 112.8297 - mae: 7.6078 - val_loss: 61.2272 - val_mae: 6.1523\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 112.3205 - mae: 7.5885 - val_loss: 60.8922 - val_mae: 6.1291\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 111.9183 - mae: 7.5748 - val_loss: 60.4909 - val_mae: 6.1026\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 111.5029 - mae: 7.5561 - val_loss: 60.0345 - val_mae: 6.0732\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 111.0914 - mae: 7.5359 - val_loss: 59.6539 - val_mae: 6.0474\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 110.7051 - mae: 7.5176 - val_loss: 59.2635 - val_mae: 6.0217\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 110.3239 - mae: 7.5009 - val_loss: 58.8894 - val_mae: 5.9973\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 109.9717 - mae: 7.4892 - val_loss: 58.6339 - val_mae: 5.9807\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 109.6068 - mae: 7.4792 - val_loss: 58.3221 - val_mae: 5.9601\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 109.2596 - mae: 7.4651 - val_loss: 57.9370 - val_mae: 5.9342\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 108.8958 - mae: 7.4473 - val_loss: 57.5955 - val_mae: 5.9110\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 108.5377 - mae: 7.4349 - val_loss: 57.3067 - val_mae: 5.8918\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 108.2377 - mae: 7.4275 - val_loss: 57.0113 - val_mae: 5.8736\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 107.8974 - mae: 7.4147 - val_loss: 56.7204 - val_mae: 5.8549\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 107.5693 - mae: 7.4012 - val_loss: 56.3684 - val_mae: 5.8307\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 107.2195 - mae: 7.3875 - val_loss: 56.0997 - val_mae: 5.8134\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 106.9596 - mae: 7.3877 - val_loss: 55.9064 - val_mae: 5.8022\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 106.6060 - mae: 7.3718 - val_loss: 55.5465 - val_mae: 5.7762\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 106.2981 - mae: 7.3575 - val_loss: 55.2248 - val_mae: 5.7535\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.9702 - mae: 7.3414 - val_loss: 54.9113 - val_mae: 5.7307\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.6724 - mae: 7.3277 - val_loss: 54.6149 - val_mae: 5.7102\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.4083 - mae: 7.3152 - val_loss: 54.2935 - val_mae: 5.6900\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 105.1187 - mae: 7.3060 - val_loss: 54.0841 - val_mae: 5.6764\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 104.8660 - mae: 7.3038 - val_loss: 53.9506 - val_mae: 5.6669\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 104.5739 - mae: 7.2961 - val_loss: 53.7027 - val_mae: 5.6527\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 104.3291 - mae: 7.2860 - val_loss: 53.4003 - val_mae: 5.6384\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 104.0510 - mae: 7.2706 - val_loss: 53.1597 - val_mae: 5.6264\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 103.8121 - mae: 7.2621 - val_loss: 52.9435 - val_mae: 5.6147\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 103.5574 - mae: 7.2537 - val_loss: 52.7072 - val_mae: 5.6021\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 103.3143 - mae: 7.2445 - val_loss: 52.4678 - val_mae: 5.5894\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 103.0576 - mae: 7.2397 - val_loss: 52.3068 - val_mae: 5.5792\n",
      "103.05760192871094 : loss history ----\n",
      "7.239691734313965 : mae history ----\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fourth experiment\n",
    "\n",
    "# we do a trail experiment\n",
    "\n",
    "ExpResults = []\n",
    "\n",
    "expOptimizers = { \"SGD\" : keras.optimizers.SGD(), \"Nesterov\" :  keras.optimizers.SGD(nesterov = True) ,  \"Momentum\" : keras.optimizers.SGD(momentum=0.5), \"Adam\" : keras.optimizers.Adam() }\n",
    "\n",
    "\n",
    "for optName,opt in expOptimizers.items():\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    run_logdir = get_run_logdir(\"opt\",opt)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    model = build_model(defaultNOL,defaultNeuronsOnLayer,opt,defaultLR)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "    history.history['loss'].sort()\n",
    "    \n",
    "    lossHis = history.history[\"loss\"][0]\n",
    "    print(str(lossHis) + \" : loss history ----\")\n",
    "    \n",
    "    history.history['mae'].sort()\n",
    "    maeHis = history.history['mae'][0]\n",
    "    print(str(maeHis) + \" : mae history ----\")\n",
    "\n",
    "    ExpResults.append((optName,lossHis,maeHis))\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pickle_out = open(\"opt.pickle\",\"wb\")\n",
    "pickle.dump(ExpResults, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "cleanSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "033d7a9a-6618-4285-b502-38817889bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 117097.6406 - mae: 123.6391 - val_loss: 104.6918 - val_mae: 8.3816\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 151.6685 - mae: 9.1904 - val_loss: 61.9500 - val_mae: 6.4389\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.8230 - mae: 7.6377 - val_loss: 47.2934 - val_mae: 5.3977\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.2339 - mae: 7.1140 - val_loss: 43.1925 - val_mae: 5.2576\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.9217 - mae: 6.9550 - val_loss: 42.3040 - val_mae: 5.2694\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3587 - mae: 6.9521 - val_loss: 42.5274 - val_mae: 5.0696\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.2858 - mae: 6.7735 - val_loss: 40.8609 - val_mae: 5.0941\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.3857 - mae: 6.7388 - val_loss: 43.7928 - val_mae: 5.4038\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 87.1998 - mae: 6.9336 - val_loss: 40.8447 - val_mae: 5.0046\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.2868 - mae: 6.6882 - val_loss: 44.0320 - val_mae: 5.4223\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.0560 - mae: 6.8589 - val_loss: 40.6689 - val_mae: 5.1115\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.4484 - mae: 6.8023 - val_loss: 47.3865 - val_mae: 5.7075\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3139 - mae: 6.7669 - val_loss: 43.9890 - val_mae: 5.4235\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.7410 - mae: 6.8169 - val_loss: 40.4068 - val_mae: 5.0640\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 84.4807 - mae: 6.7848 - val_loss: 40.1983 - val_mae: 4.9953\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 85.3348 - mae: 6.7452 - val_loss: 41.0769 - val_mae: 4.9800\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 84.1991 - mae: 6.5329 - val_loss: 76.1879 - val_mae: 7.4965\n",
      "Epoch 00017: early stopping\n",
      "84.1990966796875 : loss history ----\n",
      "6.532925128936768 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2030.7059 - mae: 25.5772 - val_loss: 66.5712 - val_mae: 6.5983\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.0625 - mae: 6.7221 - val_loss: 28.8802 - val_mae: 4.3820\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 79.6298 - mae: 6.2815 - val_loss: 30.1814 - val_mae: 4.8472\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.6043 - mae: 6.3162 - val_loss: 30.1315 - val_mae: 4.7741\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.7741 - mae: 6.2822 - val_loss: 28.7603 - val_mae: 4.6498\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.3203 - mae: 6.3558 - val_loss: 29.3497 - val_mae: 4.3226\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 76.9259 - mae: 6.2547 - val_loss: 28.4897 - val_mae: 4.5632\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 76.5203 - mae: 6.2852 - val_loss: 31.9607 - val_mae: 4.9487\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.8725 - mae: 6.4029 - val_loss: 27.6004 - val_mae: 4.4061\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.0135 - mae: 6.1442 - val_loss: 32.8645 - val_mae: 5.0298\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.0141 - mae: 6.3539 - val_loss: 28.3898 - val_mae: 4.6246\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.3926 - mae: 6.2953 - val_loss: 41.6691 - val_mae: 5.6221\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 81.3385 - mae: 6.4175 - val_loss: 36.5671 - val_mae: 5.2743\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 75.2299 - mae: 6.2984 - val_loss: 27.2613 - val_mae: 4.5076\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 74.6067 - mae: 6.2011 - val_loss: 27.0880 - val_mae: 4.4307\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 75.6978 - mae: 6.2441 - val_loss: 26.9273 - val_mae: 4.2874\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.7855 - mae: 5.9524 - val_loss: 76.6960 - val_mae: 7.6965\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.3504 - mae: 6.6169 - val_loss: 26.5163 - val_mae: 4.1997\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.8798 - mae: 6.0460 - val_loss: 33.8721 - val_mae: 5.0852\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 73.8734 - mae: 6.1981 - val_loss: 28.6230 - val_mae: 4.6882\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 74.2406 - mae: 6.1647 - val_loss: 37.0588 - val_mae: 5.2885\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.9639 - mae: 6.2485 - val_loss: 41.6937 - val_mae: 5.6077\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.4075 - mae: 6.2804 - val_loss: 27.0863 - val_mae: 4.0980\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.6612 - mae: 5.9853 - val_loss: 32.9922 - val_mae: 5.0174\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 73.8773 - mae: 6.1428 - val_loss: 30.1690 - val_mae: 4.8087\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.1211 - mae: 6.0684 - val_loss: 25.4466 - val_mae: 4.2738\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.8943 - mae: 6.0007 - val_loss: 26.0594 - val_mae: 4.1062\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.4937 - mae: 5.9733 - val_loss: 30.5040 - val_mae: 4.8333\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 72.1747 - mae: 6.1864 - val_loss: 26.1290 - val_mae: 4.1083\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.2460 - mae: 5.9531 - val_loss: 26.7210 - val_mae: 4.4775\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.4157 - mae: 6.0007 - val_loss: 25.5247 - val_mae: 4.2814\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.3624 - mae: 5.8407 - val_loss: 26.7886 - val_mae: 4.4981\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.8453 - mae: 5.9521 - val_loss: 28.5408 - val_mae: 4.6669\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.5095 - mae: 5.9837 - val_loss: 31.7162 - val_mae: 4.9187\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.5624 - mae: 5.9215 - val_loss: 40.3058 - val_mae: 5.4806\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.4640 - mae: 6.2155 - val_loss: 25.8139 - val_mae: 4.0349\n",
      "Epoch 00036: early stopping\n",
      "70.36236572265625 : loss history ----\n",
      "5.840688705444336 : mae history ----\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 155039.4219 - mae: 142.2598 - val_loss: 346.6103 - val_mae: 17.0484\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 280.6159 - mae: 14.0073 - val_loss: 194.8663 - val_mae: 12.0992\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 279.8095 - mae: 13.8930 - val_loss: 228.4728 - val_mae: 14.2381\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 201.1451 - mae: 11.2458 - val_loss: 46.9245 - val_mae: 5.4228\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 127.3826 - mae: 9.0152 - val_loss: 48.5554 - val_mae: 5.4361\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.4237 - mae: 7.7433 - val_loss: 48.9293 - val_mae: 5.4606\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.3996 - mae: 7.1381 - val_loss: 41.8356 - val_mae: 5.1484\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.4440 - mae: 7.0554 - val_loss: 44.2527 - val_mae: 5.5205\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.5328 - mae: 7.0923 - val_loss: 46.7346 - val_mae: 5.3819\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 87.0299 - mae: 6.8163 - val_loss: 44.0351 - val_mae: 5.5421\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 86.1233 - mae: 7.0554 - val_loss: 41.9311 - val_mae: 5.1293\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.2069 - mae: 6.8625 - val_loss: 41.1572 - val_mae: 5.2725\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 86.7010 - mae: 7.0961 - val_loss: 49.6723 - val_mae: 5.9248\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.0718 - mae: 6.8358 - val_loss: 41.2529 - val_mae: 5.0794\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.5435 - mae: 6.7256 - val_loss: 39.5955 - val_mae: 4.9928\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.9832 - mae: 6.7975 - val_loss: 39.0726 - val_mae: 5.0142\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.4040 - mae: 6.6899 - val_loss: 50.8709 - val_mae: 5.9441\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.6541 - mae: 8.3130 - val_loss: 37.8684 - val_mae: 4.9653\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 102.4433 - mae: 7.6834 - val_loss: 45.0558 - val_mae: 5.2910\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.2176 - mae: 6.7514 - val_loss: 50.1326 - val_mae: 5.8534\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.2005 - mae: 6.9311 - val_loss: 51.5259 - val_mae: 5.9434\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 80.5506 - mae: 6.6400 - val_loss: 37.2373 - val_mae: 4.8587\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.5931 - mae: 6.5825 - val_loss: 45.2794 - val_mae: 5.3494\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 84.0138 - mae: 6.3822 - val_loss: 45.8552 - val_mae: 5.5120\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.0903 - mae: 6.3798 - val_loss: 40.8179 - val_mae: 5.1495\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.2921 - mae: 6.1477 - val_loss: 35.6005 - val_mae: 4.6416\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 72.4760 - mae: 6.3087 - val_loss: 49.1796 - val_mae: 5.6292\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.7666 - mae: 6.2825 - val_loss: 44.7005 - val_mae: 5.3443\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.6129 - mae: 6.3134 - val_loss: 51.5941 - val_mae: 5.7750\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.4448 - mae: 6.3812 - val_loss: 45.7636 - val_mae: 5.4490\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 72.8104 - mae: 6.3035 - val_loss: 44.7464 - val_mae: 5.3266\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 73.7659 - mae: 6.1320 - val_loss: 46.0848 - val_mae: 5.4717\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 81.5351 - mae: 6.7858 - val_loss: 40.5414 - val_mae: 4.9472\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.9728 - mae: 6.4254 - val_loss: 41.2369 - val_mae: 5.0360\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.3749 - mae: 5.9523 - val_loss: 38.5684 - val_mae: 4.8238\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.3796 - mae: 7.0343 - val_loss: 59.5289 - val_mae: 6.3554\n",
      "Epoch 00036: early stopping\n",
      "68.37486267089844 : loss history ----\n",
      "5.95234489440918 : mae history ----\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fourth experiment\n",
    "\n",
    "# we do a trail experiment\n",
    "\n",
    "ExpResults = []\n",
    "\n",
    "momentumValues = [0.1, 0.5, 0.9]\n",
    "\n",
    "for mom in momentumValues:\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    run_logdir = get_run_logdir(\"mom\",mom)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    optimizerMom = keras.optimizers.SGD(momentum = mom)\n",
    "\n",
    "    \n",
    "    model = build_model(defaultNOL,defaultNeuronsOnLayer,optimizerMom,defaultLR)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=100,validation_split = 0.1, callbacks=[early_stopping_cb,tensorboard_cb])\n",
    "    history.history['loss'].sort()\n",
    "    \n",
    "    lossHis = history.history[\"loss\"][0]\n",
    "    print(str(lossHis) + \" : loss history ----\")\n",
    "    \n",
    "    history.history['mae'].sort()\n",
    "    maeHis = history.history['mae'][0]\n",
    "    print(str(maeHis) + \" : mae history ----\")\n",
    "\n",
    "    ExpResults.append((mom,lossHis,maeHis))\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pickle_out = open(\"mom.pickle\",\"wb\")\n",
    "pickle.dump(ExpResults, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "cleanSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f163179-9b69-4a43-a0c3-568cca8f138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bae0fb-f36f-416b-85d3-92c1aede7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = { \"model__n_hidden\": [0, 1, 2, 3], \"model__n_neurons\": [5,25,125],\"model__learning_rate\": [10**-6,10**-5,10**-4], \"model__optimizer\": [ keras.optimizers.SGD(),  keras.optimizers.SGD(nesterov = True) ,   keras.optimizers.SGD(momentum=0.5),  keras.optimizers.Adam() ], \"model__momentum\": [0.1,0.5,0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a3e54-0858-4893-beda-8c6fcfdbc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1.0, verbose=1)\n",
    "keras_reg = KerasRegressor(build_model, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d781e99-4fa0-4cad-8294-6e3bd31de4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7755fb223046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs,n_iter=20, cv=3, verbose=2)\n",
    "\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09fe4b-3eeb-40c7-9523-a153bf965d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
